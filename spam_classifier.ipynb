{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4ef00a-a1b6-4614-961d-4e6a405fb157",
   "metadata": {},
   "source": [
    "# import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80ebe88-ee1f-458c-8ee5-3290b415f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93aafd6f-d090-4496-8e64-5f0aa67fa248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e817e53-8b57-44cd-954c-a60ddd47e430",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9ff397-e050-4d42-b3db-13b070981178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "label         0\n",
      "text          0\n",
      "label_num     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handle missing values (replace with empty string for text data)\n",
    "data['text'].fillna('', inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "data.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3ffc3c4-14a0-4e31-ba26-de3b29f97ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      label                                               text  label_num\n",
       "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3     spam  Subject: photoshop , windows , office . cheap ...          1\n",
       "4      ham  Subject: re : indian springs\\r\\nthis deal is t...          0\n",
       "...    ...                                                ...        ...\n",
       "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...          0\n",
       "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...          0\n",
       "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...          0\n",
       "5169   ham  Subject: industrial worksheets for august 2000...          0\n",
       "5170  spam  Subject: important online banking alert\\r\\ndea...          1\n",
       "\n",
       "[5171 rows x 3 columns]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fa552-883a-4cb0-88b2-10c794c045b7",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26ebd702-e814-4425-b3b2-76757c078895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n",
      "3672\n"
     ]
    }
   ],
   "source": [
    "spam_count = data['label'].where(data['label'] == 'spam').count()\n",
    "print(spam_count)\n",
    "ham_count = data['label'].where(data['label'] == 'ham').count()\n",
    "print(ham_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8ac010b-d584-4c5f-a36e-4206cf0e98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['text']\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5716d5a3-99c3-4264-9370-7db61a257ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average text length: 227.78360085089923\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each text\n",
    "text_lengths = [len(text.split()) for text in x]\n",
    "\n",
    "# Calculate the average length\n",
    "average_length = sum(text_lengths) / len(text_lengths)\n",
    "\n",
    "print(\"Average text length:\", average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0cb7fab-2cd6-45da-9869-1d4c1ef8bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "max_len = 250 # choose an appropriate maximum length for your sequences\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f31ec48-88e4-42c1-99f7-2732b30b8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "264ba865-ead1-4f05-add3-5f158b178ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80-20 split)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_sequences, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cd609-8437-412f-bb87-aa1a158f9522",
   "metadata": {},
   "source": [
    "# Bulding keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9874509-6c15-418f-a625-d070e031d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117/117 [==============================] - 60s 460ms/step - loss: 0.5424 - accuracy: 0.7711 - val_loss: 0.5497 - val_accuracy: 0.7415\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 53s 449ms/step - loss: 0.2130 - accuracy: 0.9124 - val_loss: 0.1145 - val_accuracy: 0.9589\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 52s 446ms/step - loss: 0.0331 - accuracy: 0.9919 - val_loss: 0.0885 - val_accuracy: 0.9614\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 52s 447ms/step - loss: 0.0145 - accuracy: 0.9984 - val_loss: 0.0835 - val_accuracy: 0.9710\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 53s 450ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.0823 - val_accuracy: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a7f9e7cd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89764f4-e1d3-4b7e-a01e-a586bde195d2",
   "metadata": {},
   "source": [
    "# Evaluation of Accuracy Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b49fd606-5dcc-468f-a0f2-1a6f53369b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 3s 102ms/step - loss: 0.1041 - accuracy: 0.9681\n",
      "Test Loss: 0.10414271801710129, Test Accuracy: 0.9681159257888794\n",
      "33/33 [==============================] - 5s 100ms/step\n",
      "[[730  12]\n",
      " [ 21 272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       742\n",
      "         1.0       0.96      0.93      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n",
    "# You can also use metrics like precision, recall, and F1-score using sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49814a-0c9a-4559-9409-53931582f576",
   "metadata": {},
   "source": [
    "# Random Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00b42d47-042f-47ba-8d03-7954b7fa9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "Spam Email\n"
     ]
    }
   ],
   "source": [
    "input_your_mail = [\"PayPal Your access has been limited Dear Client, Our technical support and customer department has recently suspected activities in your account. Your Paypal account has been limited because we've noticed significant changes in your account activity. As Your payment processor, we need to understand these change better. We're always concerned about our customers security so please help us recover your account by following the link below. Restore Payment To PayPal Copyright © 1999-2020 PayPal. All rights reserved\"]\n",
    "# Print the content of the list\n",
    "# for email_content in input_your_mail:\n",
    "#     print(email_content)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_your_mail)\n",
    "max_len = 250\n",
    "\n",
    "# Pad sequences\n",
    "input_data = pad_sequences(input_sequences, maxlen=max_len)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(input_data)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "if y_pred==1:\n",
    "    print(\"Spam Email\")\n",
    "else:\n",
    "    print(\"Ham Email\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
